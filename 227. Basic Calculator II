'''
first identify the sign, then calculate with num. Since the first number is not with a sign, it's default to '+'
'''
class Solution(object):
	def calculate(self, s):
		stack = []
		sign = '+'
		num = 0
		for i in range(len(s)):
			# print(stack, num)
			if s[i].isdigit():
				num = num * 10 + ord(s[i])-ord("0")
			if (not s[i].isdigit() and not s[i].isspace()) or i == len(s)-1:
				if sign == '+':
					stack.append(num)
				if sign == '-':
					stack.append(-num)
				if sign == '*':
					stack.append(stack.pop() * num)
				if sign == '/':
					stack.append(int(stack.pop() / num))
				sign = s[i]
				num = 0

		return sum(stack)	
    
